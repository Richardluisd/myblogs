{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"set spark.sql.streaming.schemaInference=true\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T22:49:35.7796236Z",
              "session_start_time": "2022-12-02T22:49:35.8211047Z",
              "execution_start_time": "2022-12-02T22:53:29.2824222Z",
              "execution_finish_time": "2022-12-02T22:53:32.4236522Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "DataFrame[key: string, value: string]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_stream = spark \\\r\n",
        "    .readStream \\\r\n",
        "    .format('parquet') \\\r\n",
        "    .load('abfss://raw@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy_OLTP/Sales/*/*/*/*.parquet')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:07:42.7124152Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:10:41.6797914Z",
              "execution_finish_time": "2022-12-02T21:11:11.3062937Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stream.isStreaming"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:08:03.8183845Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:11:11.4303268Z",
              "execution_finish_time": "2022-12-02T21:11:11.6382238Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from delta import *"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T22:49:35.7810664Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T22:53:32.5510645Z",
              "execution_finish_time": "2022-12-02T22:53:32.7307451Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_proceess = df_stream.writeStream.format(\"delta\") \\\r\n",
        "    .option('checkpointLocation','abfss://std@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy/Sales_demo02_checkpointLocation') \\\r\n",
        "    .option('path','abfss://std@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy/Sales_demo02/') \\\r\n",
        "    .start()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:10:31.7979694Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:11:12.0503115Z",
              "execution_finish_time": "2022-12-02T21:11:29.2841998Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_proceess.status"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:12:54.7298633Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:12:54.8555134Z",
              "execution_finish_time": "2022-12-02T21:12:55.017168Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_proceess.stop()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:26:30.1215061Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:26:30.2754312Z",
              "execution_finish_time": "2022-12-02T21:26:30.4440069Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import substring, isnull, col, regexp_replace, current_timestamp, lit, month, dayofmonth, year, to_date, lpad, input_file_name, coalesce "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T22:49:42.656775Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T22:53:32.8663081Z",
              "execution_finish_time": "2022-12-02T22:53:33.0433594Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 3, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxFilesPerTrigger = 1\r\n",
        "path_source_completed = 'abfss://raw@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy_OLTP/Sales/*/*/*/*.parquet'\r\n",
        "primarykey = 'salelineid'\r\n",
        "metadata_columns = 'load_date, type_process'\r\n",
        "typeProcess = 'inc'\r\n",
        "partitionBy = None\r\n",
        "level = 'month'\r\n",
        "path_destination_completed = 'abfss://std@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy/Sales_demo02/'\r\n",
        "repartition_num_files = 32\r\n",
        "path_deltaCheckpointPath = 'abfss://std@adlsopenclassanalytics.dfs.core.windows.net/Cornerchy/Sales_demo02_checkpointPath/'"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T23:24:56.8329844Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T23:24:56.9746651Z",
              "execution_finish_time": "2022-12-02T23:24:57.1692837Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def allColumns(df, metadata_columns):\r\n",
        "    return [column for column in df.columns if column not in metadata_columns]\r\n",
        "    \r\n",
        "def generatePKs(primaryKeys):\r\n",
        "    pks_dict = dict()\r\n",
        "    for index, value in enumerate(primaryKeys):\r\n",
        "        pks_dict[f\"deltaTable.{value}\"] = f\"incTable.{value}\"\r\n",
        "    return str(pks_dict).replace(\"{\", \"\").replace(\"}\",\"\").replace(\"'\",\"\").replace(\": \", \" <=> \").replace(\",\", \" and\")\r\n",
        "\r\n",
        "def checkDeltaFolder(path):\r\n",
        "    try:\r\n",
        "        DeltaTable.forPath(spark, path)\r\n",
        "        return True\r\n",
        "    except Exception as e:\r\n",
        "        return False"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T22:49:49.9432131Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T22:53:33.4934518Z",
              "execution_finish_time": "2022-12-02T22:53:33.6699331Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsertToDelta(microBatchOutputDF, batchId, primarykey, metadata_columns, partitionBy, level, path_destination_completed, repartition_num_files, typeProcess):\r\n",
        "    if primarykey == None or primarykey == \"\":\r\n",
        "        columns = allColumns(microBatchOutputDF, metadata_columns.split(','))\r\n",
        "        primaryKeys = generatePKs(columns)\r\n",
        "    else:\r\n",
        "        columns = primarykey.split(\",\")\r\n",
        "        primaryKeys = generatePKs(columns)\r\n",
        "        microBatchOutputDF = microBatchOutputDF.withColumn(\"load_date\", current_timestamp())\r\n",
        "        microBatchOutputDF = microBatchOutputDF.withColumn(\"type_process\", lit(typeProcess))\r\n",
        "    \r\n",
        "    if checkDeltaFolder(path_destination_completed):\r\n",
        "        print (f\"upsertToDelta: {batchId} - Merge\")\r\n",
        "        curatedTable = DeltaTable.forPath(spark, path_destination_completed)\r\n",
        "        curatedTable.alias(\"deltaTable\").merge(\r\n",
        "            microBatchOutputDF.alias(\"incTable\"),primaryKeys) \\\r\n",
        "            .whenMatchedUpdateAll() \\\r\n",
        "            .whenNotMatchedInsertAll() \\\r\n",
        "        .execute()\r\n",
        "    else:\r\n",
        "        print (f\"upsertToDelta: {batchId} - Full\")\r\n",
        "        if partitionBy == None or partitionBy == \"\":\r\n",
        "            microBatchOutputDF.write.format(\"delta\").mode(\"overwrite\").option(\"escape\",\"\\\"\").save(path_destination_completed)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T23:13:29.984506Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T23:13:30.1293433Z",
              "execution_finish_time": "2022-12-02T23:13:30.3023181Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opción trigger one para versiones de spark a partir de 3.3 y procesamiento por lotes\r\n",
        "df_proceess = (spark.readStream.option(\"maxFilesPerTrigger\", maxFilesPerTrigger)\r\n",
        "    .option(\"maxFileAge\", 0).format('parquet').option(\"inferschema\", True)\r\n",
        "    .load(path_source_completed).withColumn(\"filename\", input_file_name())\r\n",
        "    .writeStream.format('delta')\r\n",
        "    .trigger(availableNow=True) \\\r\n",
        "    .foreachBatch(lambda microBatchOutputDF, batchId: upsertToDelta(microBatchOutputDF, batchId, primarykey, metadata_columns, partitionBy, level, path_destination_completed, repartition_num_files, typeProcess))\r\n",
        "    .outputMode(\"update\")\r\n",
        "    .option('checkpointLocation',path_deltaCheckpointPath) \\\r\n",
        "    .start() \\\r\n",
        "    .awaitTermination()\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T23:20:29.9296551Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T23:20:30.0732641Z",
              "execution_finish_time": "2022-12-02T23:21:03.4279116Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upsertToDelta: 11 - Merge\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_proceess.status"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-12-02T23:15:59.228386Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-12-02T23:16:41.3009671Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_proceess.stop()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess",
              "session_id": "29",
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T21:48:54.6749402Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T21:48:54.8377062Z",
              "execution_finish_time": "2022-12-02T21:48:55.009285Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess, 29, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'stop'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-336c7419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_proceess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'stop'"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opción para simular trigger one verificando el estado del streaming\r\n",
        "df_proceess = (spark.readStream.option(\"maxFilesPerTrigger\", maxFilesPerTrigger)\r\n",
        "    .option(\"maxFileAge\", 0).format('parquet').option(\"inferschema\", True)\r\n",
        "    .load(path_source_completed).withColumn(\"filename\", input_file_name())\r\n",
        "    .writeStream.format('delta')\r\n",
        "    .foreachBatch(lambda microBatchOutputDF, batchId: upsertToDelta(microBatchOutputDF, batchId, primarykey, metadata_columns, partitionBy, level, path_destination_completed, repartition_num_files, typeProcess))\r\n",
        "    .outputMode(\"update\")\r\n",
        "    .option('checkpointLocation',path_deltaCheckpointPath) \\\r\n",
        "    .start()\r\n",
        ")\r\n",
        "\r\n",
        "import time\r\n",
        "print(df_proceess.isActive)\r\n",
        "print(df_proceess.status)\r\n",
        "time.sleep(30)\r\n",
        "\r\n",
        "while df_proceess.status[\"isDataAvailable\"]:\r\n",
        "    print(\"wait for load stream...\")\r\n",
        "    time.sleep(30)\r\n",
        "print(\"stopping stream...\")\r\n",
        "df_proceess.stop()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DataProcess31",
              "session_id": "0",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-12-02T23:25:06.6224606Z",
              "session_start_time": null,
              "execution_start_time": "2022-12-02T23:25:06.7450173Z",
              "execution_finish_time": "2022-12-02T23:25:46.5625909Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DataProcess31, 0, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n{'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\nstopping stream...\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
